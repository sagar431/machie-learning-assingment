{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40dbbd4f",
   "metadata": {},
   "source": [
    " 1. What is the difference between supervised and unsupervised learning? Give some examples to\n",
    "illustrate your point.\n",
    "2. Mention a few unsupervised learning applications.\n",
    "3. What are the three main types of clustering methods? Briefly describe the characteristics of each.\n",
    "\n",
    "4. Explain how the k-means algorithm determines the consistency of clustering.\n",
    "\n",
    "5. With a simple illustration, explain the key difference between the k-means and k-medoids\n",
    "algorithms.\n",
    "\n",
    "6. What is a dendrogram, and how does it work? Explain how to do it.\n",
    "\n",
    "7. What exactly is SSE? What role does it play in the k-means algorithm?\n",
    "\n",
    "8. With a step-by-step algorithm, explain the k-means procedure.\n",
    "\n",
    "9. In the sense of hierarchical clustering, define the terms single link and complete link.\n",
    "\n",
    "10. How does the apriori concept aid in the reduction of measurement overhead in a business\n",
    "basket analysis? Give an example to demonstrate your point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567217f5",
   "metadata": {},
   "source": [
    "# Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f882e8b",
   "metadata": {},
   "source": [
    "1. Supervised learning is a machine learning approach where the model is trained on labeled data, which means that the input data is already labeled with the output or target variable. Examples include image classification, speech recognition, and sentiment analysis. In contrast, unsupervised learning involves training the model on unlabeled data, where the algorithm identifies patterns or structures in the data without being given any pre-defined labels. Examples include clustering, anomaly detection, and dimensionality reduction.\n",
    "\n",
    "2. Some examples of unsupervised learning applications include customer segmentation for marketing, anomaly detection in fraud detection, and image segmentation for computer vision.\n",
    "\n",
    "3. The three main types of clustering methods are hierarchical clustering, partitioning clustering, and density-based clustering. Hierarchical clustering involves creating a hierarchy of clusters, where each cluster is a subset of the previous cluster. Partitioning clustering divides the data into non-overlapping clusters, and density-based clustering groups together areas of high density in the data.\n",
    "\n",
    "4. The k-means algorithm determines the consistency of clustering by minimizing the within-cluster sum of squares (WCSS) metric. The algorithm calculates the distance between each point and the centroid of each cluster and assigns the point to the closest cluster. The algorithm repeats this process until the centroids no longer change.\n",
    "\n",
    "5. The key difference between the k-means and k-medoids algorithms is that k-medoids uses actual data points as cluster centers, while k-means uses the mean of data points. In k-medoids, the algorithm iteratively selects a random set of points as the initial cluster centers and assigns each point to the closest cluster. The algorithm then updates the medoid of each cluster until convergence.\n",
    "\n",
    "6. A dendrogram is a visualization tool that shows the hierarchical relationship between data points or clusters. It works by plotting the distances between each point or cluster on the y-axis and the corresponding data points or clusters on the x-axis. The algorithm merges the points or clusters with the shortest distance first and continues until all points or clusters are merged into one.\n",
    "\n",
    "7. SSE stands for the sum of squared errors, which is a metric used in the k-means algorithm to evaluate the quality of clustering. It measures the total distance between each point and its centroid within a cluster. The algorithm aims to minimize the SSE by adjusting the positions of the centroids.\n",
    "\n",
    "8. The k-means algorithm procedure can be summarized in the following steps:\n",
    "- Choose the number of clusters (k).\n",
    "- Randomly initialize the centroids for each cluster.\n",
    "- Assign each point to the closest centroid.\n",
    "- Calculate the mean of each cluster and update the centroid position.\n",
    "- Repeat the previous two steps until the centroids no longer change.\n",
    "\n",
    "9. Single link and complete link are two methods used in hierarchical clustering to define the distance between clusters. Single link measures the distance between the two closest points of different clusters, while complete link measures the distance between the two farthest points of different clusters.\n",
    "\n",
    "10. The apriori concept aids in the reduction of measurement overhead in a business basket analysis by identifying common itemsets in a large dataset of transactions. The concept involves finding frequent itemsets, or sets of items that are frequently purchased together, and using those itemsets to make recommendations or improve marketing strategies. For example, a grocery store may use the apriori concept to identify which items are commonly purchased together and use that information to create targeted marketing campaigns or promotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04fc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
